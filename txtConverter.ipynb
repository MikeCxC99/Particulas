{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5576d327-8b0d-4060-9ab7-b17b97d728b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# --- User settings ---\n",
    "# Modify the individual components of the start and end dates as needed.\n",
    "start_year = 2025\n",
    "start_month = 8\n",
    "start_day = 7\n",
    "\n",
    "end_year = 2025\n",
    "end_month = 8\n",
    "end_day = 8\n",
    "\n",
    "# Define the names for your input and output files.\n",
    "input_filename = 'datalog.txt'\n",
    "output_filename = f\"Datalog_{start_date_str.replace('-', '')}_{end_date_str.replace('-', '')}.csv\"\n",
    "# ---------------------\n",
    "\n",
    "\n",
    "# Reconstruct the date strings from the components with proper formatting.\n",
    "start_date_str = f\"{start_year}-{start_month:02d}-{start_day:02d}\"\n",
    "end_date_str = f\"{end_year}-{end_month:02d}-{end_day:02d}\"\n",
    "\n",
    "# This list will hold all the rows that match the date criteria\n",
    "processed_rows = []\n",
    "\n",
    "# Use a try-except block to handle potential file errors\n",
    "try:\n",
    "    # Open and read the input file line by line\n",
    "    with open(input_filename, 'r') as f:\n",
    "        for line in f:\n",
    "            # Skip any empty or malformed lines to prevent errors\n",
    "            if not line.strip():\n",
    "                continue\n",
    "\n",
    "            # Split the line into its different data components\n",
    "            data_list = line.strip().strip(',').split(',')\n",
    "\n",
    "            # Extract the date string from the line\n",
    "            line_date_str = data_list[0]\n",
    "            # Convert the string to a datetime object to allow for comparison\n",
    "            line_date = datetime.strptime(line_date_str, '%Y-%m-%d').date()\n",
    "\n",
    "            # Check if the line's date is within the desired range (inclusive)\n",
    "            if start_date <= line_date <= end_date:\n",
    "                # If the date matches, process the rest of the line\n",
    "                time = data_list[1]\n",
    "                unit = data_list[2].split(':')[1].strip()\n",
    "\n",
    "                # Create a dictionary to hold the data for this row\n",
    "                row_dict = {\n",
    "                    'Date': line_date_str,\n",
    "                    'Time': time,\n",
    "                    'Unit': unit\n",
    "                }\n",
    "\n",
    "                # Loop through the sensor readings (S1, S2, etc.)\n",
    "                for item in data_list[3:]:\n",
    "                    key, value = item.split(':')\n",
    "                    # Add each sensor reading to the dictionary\n",
    "                    row_dict[key.strip()] = float(value.strip())\n",
    "\n",
    "                # Append the processed dictionary to our list of rows\n",
    "                processed_rows.append(row_dict)\n",
    "\n",
    "    # After checking all lines, see if we found any matching rows\n",
    "    if processed_rows:\n",
    "        # Create the final DataFrame from the list of dictionaries\n",
    "        final_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "        # Save the final DataFrame to a CSV file, without the pandas index\n",
    "        final_df.to_csv(output_filename, index=False)\n",
    "        print(f\"Processing complete. Data between {start_date_str} and {end_date_str} has been saved to '{output_filename}'.\")\n",
    "    else:\n",
    "        print(\"No data was found within the specified date range.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The input file '{input_filename}' was not found. Please make sure the file is in the same directory as the script.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "291c64ea-9fa3-49dc-b0bc-1820af9932ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully removed empty lines from 'DatalogAntiguo.txt' and saved to 'datalog_cleaned.txt'.\n",
      "Processing complete. Data has been saved to 'Datalog.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# --- User settings ---\n",
    "# Define the names for your input and output files.\n",
    "input_filename = 'DatalogAntiguo.txt'\n",
    "cleaned_filename = 'datalog_cleaned.txt'\n",
    "output_filename = 'Datalog.csv'\n",
    "# ---------------------\n",
    "\n",
    "# --- Clean the input file ---\n",
    "try:\n",
    "    with open(input_filename, 'r') as f_in, open(cleaned_filename, 'w') as f_out:\n",
    "        for line in f_in:\n",
    "            if line.strip():\n",
    "                f_out.write(line)\n",
    "    print(f\"Successfully removed empty lines from '{input_filename}' and saved to '{cleaned_filename}'.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The input file '{input_filename}' was not found.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during file cleaning: {e}\")\n",
    "    exit()\n",
    "# --------------------------\n",
    "\n",
    "# This list will hold all the rows of data\n",
    "processed_rows = []\n",
    "\n",
    "# Use a try-except block to handle potential file errors\n",
    "try:\n",
    "    # Open and read the cleaned input file line by line\n",
    "    with open(cleaned_filename, 'r') as f:\n",
    "        for line in f:\n",
    "            # Skip any empty or malformed lines to prevent errors\n",
    "            if not line.strip():\n",
    "                continue\n",
    "\n",
    "            # Use regex to find all sensor readings in the line\n",
    "            sensor_readings = re.findall(r'(S\\d+):\\s*(-?\\d+\\.\\d+)\\s*C\\s*°,?', line)\n",
    "\n",
    "            # Create a dictionary to hold the data for this row\n",
    "            row_dict = {}\n",
    "\n",
    "            # Add each sensor reading to the dictionary\n",
    "            for key, value in sensor_readings:\n",
    "                row_dict[key] = float(value)\n",
    "\n",
    "            # Append the processed dictionary to our list of rows\n",
    "            if row_dict:\n",
    "                processed_rows.append(row_dict)\n",
    "\n",
    "    # After checking all lines, see if we found any matching rows\n",
    "    if processed_rows:\n",
    "        # Create the final DataFrame from the list of dictionaries\n",
    "        final_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "        # Reorder columns to have S0, S1, S2, etc. in order\n",
    "        final_df = final_df.reindex(sorted(final_df.columns, key=lambda x: int(x[1:])), axis=1)\n",
    "\n",
    "        # Save the final DataFrame to a CSV file, without the pandas index\n",
    "        final_df.to_csv(output_filename, index=False)\n",
    "        print(f\"Processing complete. Data has been saved to '{output_filename}'.\")\n",
    "    else:\n",
    "        print(\"No data was found in the input file.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The cleaned file '{cleaned_filename}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68e69172-3b35-49fa-a653-2e08553e9579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully removed empty lines from '1730.TXT' and saved to 'datalog_cleaned_A.txt'.\n",
      "No processable data was found in the input file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# --- User settings ---\n",
    "# Define the names for your input and output files.\n",
    "input_filename = '1730.TXT'\n",
    "cleaned_filename = 'datalog_cleaned_A.txt'\n",
    "output_filename = 'Datalog.csv_A'\n",
    "# ---------------------\n",
    "\n",
    "# --- Clean the input file ---\n",
    "try:\n",
    "    with open(input_filename, 'r') as f_in, open(cleaned_filename, 'w') as f_out:\n",
    "        for line in f_in:\n",
    "            # Only write lines that are not empty to the cleaned file\n",
    "            if line.strip():\n",
    "                f_out.write(line)\n",
    "    print(f\"Successfully removed empty lines from '{input_filename}' and saved to '{cleaned_filename}'.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The input file '{input_filename}' was not found.\")\n",
    "    exit() # Stop the script if the input file is missing\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during file cleaning: {e}\")\n",
    "    exit() # Stop the script on other cleaning errors\n",
    "# --------------------------\n",
    "\n",
    "# This list will hold all the rows for the final CSV\n",
    "processed_rows = []\n",
    "# Variables to hold the last seen date and time\n",
    "current_date = None\n",
    "current_time = None\n",
    "\n",
    "# Use a try-except block to handle potential file errors\n",
    "try:\n",
    "    # Open and read the cleaned input file line by line\n",
    "    with open(cleaned_filename, 'r') as f:\n",
    "        for line in f:\n",
    "            # --- Timestamp Handling ---\n",
    "            # Check if the line contains a full date and time stamp\n",
    "            # Regex to find a date (YYYY-MM-DD) and a time (HH:MM:SS)\n",
    "            timestamp_match = re.search(r'(\\d{4}-\\d{2}-\\d{2}),(\\d{2}:\\d{2}:\\d{2})', line)\n",
    "            if timestamp_match:\n",
    "                # If a timestamp is found, update the current date and time for subsequent lines\n",
    "                current_date = timestamp_match.group(1)\n",
    "                current_time = timestamp_match.group(2)\n",
    "\n",
    "            # --- Data Extraction ---\n",
    "            # Use regex to find all sensor readings in the current line\n",
    "            # This looks for patterns like \"S#: ##.# C°\"\n",
    "            sensor_readings = re.findall(r'(S\\d+):\\s*(-?\\d+\\.\\d+)\\s*C\\s*°?', line)\n",
    "\n",
    "            # --- Row Creation Logic ---\n",
    "            # A row is only created if:\n",
    "            # 1. A timestamp has already been found in the file (current_date is not None)\n",
    "            # 2. The current line actually contains sensor data (sensor_readings is not empty)\n",
    "            if current_date and sensor_readings:\n",
    "                # Create a dictionary to hold the data for this row\n",
    "                row_dict = {\n",
    "                    'Date': current_date,\n",
    "                    'Time': current_time,\n",
    "                    'Unit': 'C°' # Set the unit to C° as it's consistent\n",
    "                }\n",
    "\n",
    "                # Add each sensor reading found on this line to the dictionary\n",
    "                for key, value in sensor_readings:\n",
    "                    row_dict[key] = float(value)\n",
    "\n",
    "                # Append the completed dictionary to our list of rows\n",
    "                processed_rows.append(row_dict)\n",
    "\n",
    "    # --- DataFrame Creation and Export ---\n",
    "    # After checking all lines, see if we found any valid data\n",
    "    if processed_rows:\n",
    "        # Create the final DataFrame from the list of dictionaries\n",
    "        final_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "        # Define the desired column order for the CSV\n",
    "        # Get all columns that start with 'S' and sort them numerically\n",
    "        sensor_columns = sorted([col for col in final_df.columns if col.startswith('S')], key=lambda x: int(x[1:]))\n",
    "        column_order = ['Date', 'Time', 'Unit'] + sensor_columns\n",
    "\n",
    "        # Reorder the DataFrame columns and fill missing sensor values with empty strings\n",
    "        final_df = final_df.reindex(columns=column_order).fillna('')\n",
    "\n",
    "        # Save the final DataFrame to a CSV file, without the pandas index\n",
    "        final_df.to_csv(output_filename, index=False)\n",
    "        print(f\"Processing complete. Data has been saved to '{output_filename}'.\")\n",
    "    else:\n",
    "        print(\"No processable data was found in the input file.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The cleaned file '{cleaned_filename}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0150eb05-e9e7-4053-900d-777399f1e9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Data from '1730.TXT' has been saved to 'Datalog_A.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# --- User settings ---\n",
    "# Define the names for your input and output files.\n",
    "input_filename = '1730.TXT'\n",
    "cleaned_filename = 'datalog_cleaned_A.txt'\n",
    "output_filename = 'Datalog_A.csv'\n",
    "# ---------------------\n",
    "# This list will hold all the rows for the final CSV\n",
    "processed_rows = []\n",
    "\n",
    "try:\n",
    "    with open(input_filename, 'r') as f:\n",
    "        for line in f:\n",
    "            # --- Skip Header Line ---\n",
    "            # If the line is empty or a header, skip it and continue to the next one\n",
    "            if not line.strip() or 'Inicio de registro' in line:\n",
    "                continue\n",
    "\n",
    "            # --- Data Extraction ---\n",
    "            # Split the line by commas to separate the parts\n",
    "            parts = line.strip().split(',')\n",
    "\n",
    "            # Extract date and time from the first two parts\n",
    "            date_str = parts[0]\n",
    "            time_str = parts[1]\n",
    "\n",
    "            # Create a dictionary for the row with the basic information\n",
    "            row_dict = {\n",
    "                'Date': date_str,\n",
    "                'Time': time_str,\n",
    "                'Unit': 'C°' # The unit is consistent, so we can set it directly\n",
    "            }\n",
    "\n",
    "            # --- Sensor Reading Extraction ---\n",
    "            # The rest of the line contains the sensor data\n",
    "            # We re-join the remaining parts in case a comma was in a value\n",
    "            sensor_data_string = ','.join(parts[2:])\n",
    "\n",
    "            # Use regex to find all sensor readings (e.g., \"S1: 20.38\")\n",
    "            sensor_readings = re.findall(r'(S\\d+):\\s*(-?\\d+\\.?\\d*)', sensor_data_string)\n",
    "\n",
    "            # Add each found sensor reading to our dictionary\n",
    "            for key, value in sensor_readings:\n",
    "                row_dict[key] = float(value)\n",
    "\n",
    "            # Add the completed row to our list\n",
    "            processed_rows.append(row_dict)\n",
    "\n",
    "\n",
    "    # --- DataFrame Creation and Export ---\n",
    "    if processed_rows:\n",
    "        # Create the final DataFrame from our list of row dictionaries\n",
    "        final_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "        # Get all columns that start with 'S' and sort them numerically for clean ordering\n",
    "        sensor_columns = sorted([col for col in final_df.columns if col.startswith('S')], key=lambda x: int(x[1:]))\n",
    "        \n",
    "        # Define the final column order\n",
    "        column_order = ['Date', 'Time', 'Unit'] + sensor_columns\n",
    "\n",
    "        # Reorder the DataFrame and fill any missing sensor values with an empty string\n",
    "        final_df = final_df.reindex(columns=column_order).fillna('')\n",
    "\n",
    "        # Save the DataFrame to a CSV file\n",
    "        final_df.to_csv(output_filename, index=False)\n",
    "        print(f\"Processing complete. Data from '{input_filename}' has been saved to '{output_filename}'.\")\n",
    "    else:\n",
    "        print(f\"No processable data was found in '{input_filename}'.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The input file '{input_filename}' was not found. Please make sure it is in the same directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2a9572-3c45-4885-ad70-fcc75f524d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
